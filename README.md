# üß† Roteiro Explicativo do Projeto de Machine Learning com Random Forest

## üìå 1. Objetivo do Projeto  
O objetivo deste projeto foi construir um modelo de *Machine Learning* capaz de classificar registros de rede como **‚Äúnormal‚Äù** ou **‚Äúanomaly‚Äù**, utilizando dados com vari√°veis num√©ricas e categ√≥ricas, como parte de uma tarefa de detec√ß√£o de intrus√µes (ou comportamento an√¥malo).

---

## ‚öôÔ∏è 2. Pr√©-processamento dos Dados  
O *dataset* original possu√≠a **42 colunas**, sendo **3** delas do tipo *object* (categ√≥ricas):

- `protocol_type`  
- `service`  
- `flag`

Essas colunas n√£o poderiam ser usadas diretamente em modelos como o **KNN**, pois ele depende de **c√°lculos de dist√¢ncia entre pontos**, o que n√£o funciona com *strings* ou vari√°veis categ√≥ricas.

Por isso, as vari√°veis categ√≥ricas foram transformadas em vari√°veis num√©ricas utilizando o **LabelEncoder** do `sklearn`, que atribui um n√∫mero inteiro para cada valor √∫nico da vari√°vel categ√≥rica.

---

## üß™ 3. Escolha do Modelo: Por que Random Forest (RFC)?  
Inicialmente, foi considerado o uso de **KNN (K-Nearest Neighbors)**.  
Por√©m, o KNN √© sens√≠vel a:

- Escala dos dados  
- Vari√°veis categ√≥ricas  
- Dimensionalidade alta  

O **Random Forest Classifier (RFC)** foi escolhido por v√°rias raz√µes:

- Lida bem com vari√°veis categ√≥ricas convertidas  
- √â robusto a *outliers*  
- Possui boa capacidade de generaliza√ß√£o  
- Tem pouco risco de *overfitting* se bem parametrizado  
- Fornece import√¢ncia das *features*

---

## üìä 4. Treinamento e Avalia√ß√£o do Modelo  
Os dados foram divididos em `X_train`, `X_test`, `y_train`, `y_test`.

Ap√≥s o treinamento, o modelo foi avaliado com as seguintes m√©tricas:

- **Acur√°cia no Treinamento:** 1.0000  
- **Acur√°cia no Teste:** 1.0000  

Tamb√©m foi realizada uma **valida√ß√£o cruzada com 5 folds**, resultando em:

- **M√©dia de Acur√°cia na Valida√ß√£o Cruzada:** 0.9972  
- **Desvio Padr√£o:** 0.0004  

Esses resultados mostram que o modelo teve uma performance excepcional, mantendo **alta acur√°cia** e **consist√™ncia** nos diferentes subconjuntos dos dados. Isso refor√ßa que ele **generaliza bem**, e **n√£o est√° sofrendo de overfitting**.

---

## üìâ 5. Matriz de Confus√£o  
A matriz de confus√£o revelou um desempenho perfeito:

```
[[ 8347     0]
 [    0 14197]]
```

- 8347 exemplos de **‚Äúanomaly‚Äù** classificados corretamente  
- 14197 exemplos de **‚Äúnormal‚Äù** classificados corretamente  
- **Nenhum erro de classifica√ß√£o foi cometido**

---

## ‚úÖ 6. Conclus√£o dos Resultados  
O modelo **Random Forest** conseguiu identificar **100% das amostras corretamente**, o que √© **rar√≠ssimo**.

A **valida√ß√£o cruzada** confirmou que essa alta performance **n√£o foi por acaso**, j√° que o modelo manteve resultados est√°veis e precisos em diferentes divis√µes dos dados.

---

## üìö 7. Dificuldades e Aprendizados  
O maior desafio inicial foi lidar com as **vari√°veis categ√≥ricas** no *dataset*, especialmente porque o **KNN** (primeira op√ß√£o testada) **n√£o consegue lidar bem com esse tipo de dado** sem um tratamento cuidadoso.

Foi importante entender a diferen√ßa entre **modelos baseados em dist√¢ncia (KNN)** e **modelos baseados em √°rvores (RFC)**. Esse entendimento guiou a decis√£o de mudar para **Random Forest**.

Tamb√©m aprendi a import√¢ncia de usar **valida√ß√£o cruzada** como ferramenta para verificar se o modelo est√° realmente **generalizando**, mesmo quando a acur√°cia no teste parece perfeita.

---

## üß© 8. Poss√≠veis Melhorias Futuras  
- Testar outros modelos para compara√ß√£o, como **XGBoost** ou **Gradient Boosting**, que tamb√©m s√£o baseados em √°rvores, mas com t√©cnicas de *boosting*  
- Explorar m√©todos de **sele√ß√£o de *features*** para reduzir a dimensionalidade  
- Avaliar o modelo com **dados mais desafiadores ou desbalanceados** para testar sua robustez
